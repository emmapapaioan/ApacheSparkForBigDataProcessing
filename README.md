# Big Data Processing with Apache Spark
This repository houses a set of exercises completed as part of a university course on Big Data processing, leveraging Apache Spark, a robust unified analytics engine for large-scale data processing. The exercises encompass various data operations, including DataFrame and RDD transformations, Spark SQL queries, and graph processing.

## Project Overview
<ul>
  <li><strong>Exercise 1:</strong> A simple Spark job illustrating how to read data, execute basic transformations, and write data.</li> 

  <li><strong>Exercise 2:</strong> A Spark job that ingests a dataset of airline tweets, analyzing the text of tweets to find the most commonly used words within each sentiment category. It also identifies the primary cause   of complaints per airline.</li> 

  <li><strong>Exercise 3:</strong> A Spark job that loads a dataset of movies and carries out operations such as grouping by genre, counting movies per year, and identifying words with specific occurrences in movie titles.   </li> 

  <li><strong>Exercise 4:</strong> A Spark job that reads a dataset of web links and performs graph processing to identify vertices with the most incoming and outgoing edges. It also computes the average degree of vertices    and counts those with degrees surpassing the average.</li> 
</ul>

## Running the Project
To execute this project, Spark must be installed and configured on your system. You can then clone this repository and run the code locally.

## Dependencies
Apache Spark
Scala

<em>This repository is publicly available for educational purposes. The exercises present an overview of the capabilities and functionalities of Apache Spark.</em>
